{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßæ Mainframe JCL to Structured JSON Parser\n",
    "\n",
    "This notebook demonstrates a proof-of-concept that parses Mainframe components (`JCL`, `JCLPROC`, and `SQLLIB`) into a detailed, structured JSON format. For confidentiality reasons I am not mentioning the actual input JCL's and Output Json. \n",
    "\n",
    "## üéØ Objective\n",
    "Help application teams:\n",
    "- Analyze job execution flow\n",
    "- Identify database interactions\n",
    "- Extract SQL logic & transformations\n",
    "- Assist in modernization planning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample JCL input (pseudo)\n",
    "JCL = \"\"\"...\"\"\"  # Keep your original sample here\n",
    "\n",
    "JCLPROC = \"\"\"...\"\"\"  # Your sample PROC\n",
    "\n",
    "SQLLIB = \"\"\"...\"\"\"  # Your SQLLIB input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Structured Prompt for JCL ‚Üí JCLPROC ‚Üí SQL Extraction\n",
    "\n",
    "This prompt guides an LLM to extract structured information from three mainframe components:\n",
    "\n",
    "- **`JCL`**: Defines the main job, referencing procedures (`JCLPROC`)\n",
    "- **`JCLPROC`**: Contains job steps and datasets, often pointing to `SQLLIB` members\n",
    "- **`SQLLIB`**: Contains SQL statements ‚Äî must be deeply parsed if referenced\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Objective\n",
    "\n",
    "Generate a single, structured **JSON object** that captures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "getjson4 = f\"\"\"\n",
    "You are extracting structured information from Mainframe components: JCL, JCLPROC, and SQLLIB.\n",
    "\n",
    "- JCL defines the main job and may invoke one or more procedures (JCLPROC).\n",
    "- JCLPROC defines execution steps, often referencing SYSIN or DD statements that point to SQLLIB members.\n",
    "- SQLLIB contains SQL statements and must be fully parsed if referenced.\n",
    "\n",
    "---\n",
    "\n",
    "Your task is to generate a single, comprehensive JSON that captures the full execution hierarchy and SQL lineage.\n",
    "\n",
    "### JSON Hierarchy:\n",
    "job ‚Üí jcl_procs_called ‚Üí procs_used ‚Üí sqllib_used ‚Üí sql_operations\n",
    "\n",
    "---\n",
    "\n",
    "### JSON Structure and Fields:\n",
    "\n",
    "#### 1. `job`:\n",
    "- `name`: Job name from the JCL\n",
    "- `jcl_procs_called`: List of PROC names referenced via EXEC steps\n",
    "- `procs_used`: List of detailed PROC objects\n",
    "\n",
    "#### 2. For each `proc`:\n",
    "- `proc_name`: Name of the PROC\n",
    "- `input_files`: Only include datasets that are **PS (Physical Sequential)**, **GDG (Generation Data Groups)**, or **PDS ending in `.SQLLIB`** if used by the proc  \n",
    "  ‚ùó Do **not** include:\n",
    "  - other PDS (Partitioned Datasets) not ending with `.SQLLIB`\n",
    "- `output_files`: Same rules as above ‚Äî only include PS or GDG datasets\n",
    "- `sqllib_used`: List of referenced SQLLIB members  \n",
    "  - For each member:\n",
    "    - `member_name`: Name of the SQLLIB member (e.g., `VX20101D`)\n",
    "    - `sql_operations`: List of SQL statements with the following fields:\n",
    "      - `operation`: SQL command type (e.g., INSERT, DELETE, SELECT)  \n",
    "        ‚ùóÔ∏è **Do not include `COLLECT STATISTICS`**\n",
    "      - `query`: Full SQL text\n",
    "      - `impacted_columns`: List of columns affected by the operation\n",
    "      - `where_clause`: WHERE condition if present\n",
    "      - `group_by`: GROUP BY clause if present\n",
    "      - `order_by`: ORDER BY clause if present\n",
    "      - `transformations`: List of expressions involving functions, concatenations, calculations, or logic applied to columns  \n",
    "        - For each transformation:\n",
    "          - `expression`: The full transformed expression (e.g., `XX.ABC_DT || '00:00:00'`)\n",
    "          - `columns_involved`: List of columns used in the expression (e.g., `XX.ABC_DT`)\n",
    "          - `source_table`: The actual table (not alias) the column comes from\n",
    "      - `joins`: List of joins with:\n",
    "        - `left_table`: Use the **actual table name**, not an alias\n",
    "        - `right_table`: Use the **actual table name**, not an alias\n",
    "        - `on_clause`: The full join condition\n",
    "        - `join_type`: e.g., INNER, LEFT\n",
    "        - ‚ùó Ensure both `left_table` and `right_table` match those in `tables_involved`\n",
    "      - `unions`: If UNION/UNION ALL is used, include subqueries\n",
    "      - `subqueries`: Any SELECTs used within WHERE or FROM clauses, with the involved tables\n",
    "      - `tables_involved`: List of all tables referenced in the operation, each with:\n",
    "        - `table_name`\n",
    "        - `access_type`: e.g., SELECT, INSERT, DELETE\n",
    "\n",
    "---\n",
    "\n",
    "### Constraints:\n",
    "- ‚ùå Do **not** include datasets from unrelated PDS in `input_files` or `output_files`\n",
    "- ‚ùå Do **not** omit `.SQLLIB` datasets if used ‚Äî include them in `input_files`\n",
    "- ‚ùå Do **not** include `COLLECT STATISTICS` operations in the final JSON\n",
    "- ‚úÖ Resolve all aliases used in joins or transformations to their corresponding base table names\n",
    "- ‚úÖ SQLLIB members must be fully parsed when referenced\n",
    "- ‚úÖ Return the result in **pure JSON format only** ‚Äî no markdown, no extra text\n",
    "\n",
    "---\n",
    "\n",
    "### Input Content:\n",
    "{JCL}\n",
    "{JCLPROC}\n",
    "{SQLLIB}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# First let's do an import\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Next it's time to load the API keys into environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Check the keys\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# And now we'll create an instance of the OpenAI class\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": getjson4}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the Prompt and Get JSON (Code Cell)\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "response = response.choices[0].message.content\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "json_response = response.choices[0].message.content\n",
    "print(json_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion : OPENAI accuracy is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
